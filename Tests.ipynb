{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/washaq00/TeethOrBraces/blob/master/Tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MUNDOnLAj6L",
        "outputId": "81582797-f3e2-41d2-8846-7cac49ba44fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.1.0+cu121\n",
            "torchvision version: 0.16.0+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWMDW_aGFRFW"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "train_dir = os.path.join(os.getcwd(),\"/content/drive/MyDrive/data/train\")\n",
        "    # print(find_classes(train_dir))\n",
        "test_dir = os.path.join(os.getcwd(),\"/content/drive/MyDrive/data/test\")\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "                        transforms.Resize(size=(224, 224)),\n",
        "                        transforms.TrivialAugmentWide(num_magnitude_bins= 31),\n",
        "                        transforms.ToTensor()])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uprZX5OjdAy3"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from typing import Tuple, Dict, List #typical list is not\n",
        "\n",
        "\n",
        "\n",
        "def find_classes(dir: str) -> Tuple[List[str],Dict[str, int]]:\n",
        "    #get the class names with scanning directory (it checkes if there are any subfolder)\n",
        "    classes = sorted(entry.name for entry in os.scandir(dir) if entry.is_dir())\n",
        "\n",
        "    #show the error\n",
        "    if not classes:\n",
        "        raise FileNotFoundError(f\"Couldn't find any classes\")\n",
        "\n",
        "    #creating a Dict with name and id\n",
        "    classes_to_id = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "    return classes, classes_to_id\n",
        "\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform =None):\n",
        "        self.classes, self.classes_idx = find_classes(img_dir)\n",
        "        self.paths = list(pathlib.Path(img_dir).glob(\"*/*.png\"))\n",
        "        self.transform = transform\n",
        "\n",
        "    def load_image(self, index: int) -> Image.Image:\n",
        "        image_path = self.paths[index]\n",
        "        return Image.open(image_path)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.load_image(idx)\n",
        "        class_name = self.paths[idx].parent.name\n",
        "        class_idx = self.classes_idx[class_name]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, class_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT7Cc755dFCu"
      },
      "outputs": [],
      "source": [
        "train_data = CustomImageDataset(img_dir=train_dir,  # target folder of images\n",
        "                                    transform=train_transform)  # transforms to perform on labels (if necessary)\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize(size=(224, 224)),\n",
        "        transforms.ToTensor()])\n",
        "\n",
        "test_data = CustomImageDataset(img_dir=test_dir,\n",
        "                                   transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUU1zWhedUzY"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "NUM_WORKERS = 1\n",
        "class_names = train_data.classes\n",
        "    # print(class_names)\n",
        "    # img, label = train_data[0][0], train_data[0][1]\n",
        "    # print_image(img)\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                                  batch_size=batch_size,\n",
        "                                  num_workers=NUM_WORKERS,\n",
        "                                  shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                                 batch_size=batch_size,\n",
        "                                 num_workers=NUM_WORKERS,\n",
        "                                 shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTo_TrcxdyW8"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "VGG_types = {\n",
        "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG16\": [\n",
        "        64,\n",
        "        64,\n",
        "        \"M\",\n",
        "        128,\n",
        "        128,\n",
        "        \"M\",\n",
        "        256,\n",
        "        256,\n",
        "        256,\n",
        "        \"M\",\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        \"M\",\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        \"M\",\n",
        "    ],\n",
        "    \"VGG19\": [\n",
        "        64,\n",
        "        64,\n",
        "        \"M\",\n",
        "        128,\n",
        "        128,\n",
        "        \"M\",\n",
        "        256,\n",
        "        256,\n",
        "        256,\n",
        "        256,\n",
        "        \"M\",\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        \"M\",\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        \"M\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(VGG, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.conv_layers = self.create_conv_layers(VGG_types[\"VGG16\"])\n",
        "\n",
        "        self.fcs = nn.Sequential(\n",
        "            nn.Linear(512*8*8, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fcs(x)\n",
        "        return x\n",
        "\n",
        "    def create_conv_layers(self, architecture):\n",
        "        layers = []\n",
        "        in_channels = self.in_channels\n",
        "\n",
        "        for x in architecture:\n",
        "            if type(x) == int:\n",
        "                out_channels = x\n",
        "\n",
        "                layers += [\n",
        "                    nn.Conv2d(\n",
        "                        in_channels=in_channels,\n",
        "                        out_channels=out_channels,\n",
        "                        kernel_size=(3, 3),\n",
        "                        stride=(1, 1),\n",
        "                        padding=(1, 1),\n",
        "                    ),\n",
        "                    nn.BatchNorm2d(x),\n",
        "                    nn.ReLU(),\n",
        "                ]\n",
        "                in_channels = x\n",
        "            elif x == \"M\":\n",
        "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
        "\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxTZIAR_eOtO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from time import perf_counter\n",
        "from tqdm.auto import tqdm #progress bar\n",
        "from torch.utils.data import DataLoader\n",
        "def model_eval(model: torch.nn.Module,\n",
        "               test_data: torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               acc1):\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    loss, accuracy = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for x, y in tqdm(test_data):\n",
        "            test_logits = model(x)\n",
        "            loss += loss_fn(test_logits, y)\n",
        "            accuracy += acc1(y_true=y,y_pred= test_logits.argmax(dim=1))\n",
        "\n",
        "        loss /= len(test_data)\n",
        "        accuracy /= len(test_data)\n",
        "\n",
        "    return {\"model_name\": model.__class__.__name__,\n",
        "            \"model_loss\": loss.item(), #returns the value of tensor\n",
        "            \"model_acc\": accuracy}\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               train_data: torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               optimize,\n",
        "               acc):\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    tloss:float = 0\n",
        "    tacc:float = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch, (x, y) in enumerate(train_data):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        y_logits = model(x)\n",
        "        loss = loss_fn(y_logits, y)\n",
        "        optimize.zero_grad()\n",
        "        loss.backward()\n",
        "        optimize.step()\n",
        "        model.eval()\n",
        "\n",
        "        tloss += loss.item()\n",
        "        tacc += acc(y_true=y, y_pred=y_logits.argmax(dim=1))\n",
        "    tloss /= len(train_data)\n",
        "    tacc /= len(train_data)\n",
        "\n",
        "    return tloss, tacc\n",
        "\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              test_data: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              acc):\n",
        "    tloss: float = 0\n",
        "    tacc: float = 0\n",
        "    model.eval()\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    for x, y in test_data:\n",
        "        with torch.inference_mode():\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            test_logits = model(x)\n",
        "            loss = loss_fn(test_logits, y)\n",
        "\n",
        "            tloss += loss.item()\n",
        "            tacc += acc(y_true=y,y_pred=test_logits.argmax(dim=1))\n",
        "    tloss /= len(test_data)\n",
        "    tacc /= len(test_data)\n",
        "\n",
        "    return tloss, tacc\n",
        "\n",
        "\n",
        "def training_loop(model: torch.nn.Module,\n",
        "                  train: torch.utils.data.DataLoader,\n",
        "                  test: torch.utils.data.DataLoader,\n",
        "                  optimizer,\n",
        "                  loss_fn,\n",
        "                  acc,\n",
        "                  epochs: int = 5):\n",
        "\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []}\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                           train_data = train,\n",
        "                                           optimize= optimizer,\n",
        "                                           loss_fn = loss_fn,\n",
        "                                           acc = acc)\n",
        "\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "                                        test_data=test,\n",
        "                                        loss_fn=loss_fn,\n",
        "                                        acc=acc)\n",
        "\n",
        "        print(f\"Epoch: {epoch} train loss: {train_loss}, train acc: {train_acc}, test loss: {test_loss}, test acc: {test_acc}\")\n",
        "\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GnSYYqkeXar"
      },
      "outputs": [],
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
        "\n",
        "    Args:\n",
        "        y_true (torch.Tensor): Truth labels for predictions.\n",
        "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
        "\n",
        "    Returns:\n",
        "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
        "    \"\"\"\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv7tE8esgx1N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class TinyVgg(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2)  # default stride value is same as kernel_size\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=hidden_units * 16*16,\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.block_2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.classifier(x)\n",
        "        # print(x.shape)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3dWEXPE0KZ9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample=None, stride=1):\n",
        "        super().__init__()\n",
        "        self.expansion = 4\n",
        "        self.conv1 = nn.Conv2d(in_channels,\n",
        "                               out_channels,\n",
        "                               kernel_size=1,\n",
        "                               stride=1,\n",
        "                               padding=0,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels,\n",
        "                               out_channels,\n",
        "                               kernel_size=3,\n",
        "                               stride=stride,\n",
        "                               padding=1,\n",
        "                               bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels,\n",
        "                               out_channels*self.expansion,\n",
        "                               kernel_size=1,\n",
        "                               stride=1,\n",
        "                               padding=0,\n",
        "                               bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCbU4pyY0GvC"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import math\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, image_channels, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        #ResNet Layers\n",
        "        self.layer1 = self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
        "        self.layer2 = self._make_layer(block, layers[1], out_channels=128, stride=2)\n",
        "        self.layer3 = self._make_layer(block, layers[2], out_channels=256, stride=2)\n",
        "        self.layer4 = self._make_layer(block, layers[3], out_channels=512, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(512*4, num_classes) #fully conected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, num_residual_blocks, out_channels, stride):\n",
        "        downsample = None\n",
        "        layers = []\n",
        "\n",
        "        if stride != 1 or self.in_channels != out_channels * 4:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels,\n",
        "                          out_channels * 4,\n",
        "                          kernel_size=1,\n",
        "                          stride=stride,\n",
        "                          bias=False),\n",
        "                nn.BatchNorm2d(out_channels * 4))\n",
        "\n",
        "        layers.append(block(self.in_channels, out_channels, downsample, stride))\n",
        "        self.in_channels = out_channels*4\n",
        "\n",
        "        for i in range(num_residual_blocks - 1):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "def ResNet50(pretrained=True, img_channels=3, num_classes=2):\n",
        "\n",
        "    model = ResNet(ResNetBlock, [3,4,6,3], img_channels, num_classes)\n",
        "\n",
        "    if pretrained:\n",
        "        pretrained_dict = model_zoo.load_url(model_urls['resnet50'])\n",
        "        model_dict = model.state_dict()\n",
        "        pretrained_dict = {key.replace(\"module.\", \"\"): value for key, value in pretrained_dict.items()}\n",
        "        model_dict.update(pretrained_dict)\n",
        "        model.load_state_dict(pretrained_dict)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kZ5ULlrP-gT"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "class Net(nn.Module):\n",
        "    # conv2d_depths = [1, 2, 4, 8, 16, 32]\n",
        "    conv2d_depths = [3, 16, 32, 64, 128, 128]\n",
        "    linear_features = [2048, 1024, 2]\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # convolutional layers\n",
        "        self.conv1 = nn.Conv2d(self.conv2d_depths[0], self.conv2d_depths[1], 3, padding=1)  # 224\n",
        "        self.conv2 = nn.Conv2d(self.conv2d_depths[1], self.conv2d_depths[2], 3, padding=1)  # 112\n",
        "        self.conv3 = nn.Conv2d(self.conv2d_depths[2], self.conv2d_depths[3], 3, padding=1)  # 56\n",
        "        self.conv4 = nn.Conv2d(self.conv2d_depths[3], self.conv2d_depths[4], 3, padding=1)  # 28\n",
        "        self.conv5 = nn.Conv2d(self.conv2d_depths[4], self.conv2d_depths[5], 3, padding=1)  # 14\n",
        "        # conv2d dropout\n",
        "        self.conv2_dropout = nn.Dropout2d(0.2)\n",
        "        # pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # fully connected layers\n",
        "        self.in_features = self.conv2d_depths[-1] * 14 ** 2\n",
        "        self.linear1 = nn.Linear(self.in_features, self.linear_features[0])\n",
        "        self.linear2 = nn.Linear(self.linear_features[0], self.linear_features[1])\n",
        "        self.linear3 = nn.Linear(self.linear_features[1], self.linear_features[2])\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define forward behavior\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.conv2_dropout(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.conv2_dropout(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.conv2_dropout(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.conv2_dropout(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.conv2_dropout(x)\n",
        "\n",
        "        # flatten, otherwise it won't work\n",
        "        x = x.view(-1, self.in_features)\n",
        "\n",
        "\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear3(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEkYr5L-0aNv"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "from torchvision import models\n",
        "\n",
        "vgg = models.vgg16().to(device)\n",
        "# model_0 = ResNet50(num_classes=len(train_data.classes)).to(device)\n",
        "model_1 = Net().to(device)\n",
        "model_0= TinyVgg(input_shape = 3,\n",
        "                 hidden_units = 10,\n",
        "                 output_shape = 2).to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXDWme4sZYxj"
      },
      "outputs": [],
      "source": [
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path, from_epoch=0, valid_loss_min=np.Inf):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            \"\"\" From https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html and\n",
        "             https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "            \"\"\"\n",
        "            optimizer.zero_grad()\n",
        "            if isinstance(model, models.Inception3):\n",
        "                output, aux_output = model(data)\n",
        "                loss1 = criterion(output, target)\n",
        "                loss2 = criterion(aux_output, target)\n",
        "                loss = loss1 + 0.4*loss2\n",
        "            else:\n",
        "                output = model(data)\n",
        "                loss = criterion(output, target)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "\n",
        "        ######################\n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            output = model.forward(data)\n",
        "            loss = criterion(output, target)\n",
        "            valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "\n",
        "        # print training/validation statistics\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch + from_epoch,\n",
        "            train_loss,\n",
        "            valid_loss\n",
        "        ))\n",
        "\n",
        "        # save the model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
        "            try:\n",
        "                save_model(model, save_path)\n",
        "            except:\n",
        "                print('Could not save the model')\n",
        "            valid_loss_min = valid_loss\n",
        "\n",
        "    # return trained model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 986,
          "referenced_widgets": [
            "e57e6fc953674c188bc5ad791c1a171e",
            "f1e054fa691d48c58528d45c4d584cb5",
            "19ebbc34c50d4381a52463e325866084",
            "32e96f9d1d3942d8aa34701b52ce8e56",
            "a0deb4d2da224b679e8730772dcc2689",
            "44c7cf2da5464a7b8270f80aadb8cbf7",
            "f2e728ea8a4b4927b484d7c3f1a7b3d7",
            "f59cddc62593405b8e69f4d0f8e7f709",
            "a43d2cece97740babd30026584f9bb69",
            "90fad83f49df455cb4b5fb8c908c3fc8",
            "7be73d379e3f4cb581b9e48e05f9aa3b"
          ]
        },
        "id": "cOwXsWclg1gE",
        "outputId": "e4c31b21-775f-4028-da74-cbc6576469b0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e57e6fc953674c188bc5ad791c1a171e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 train loss: 0.6933111357934696, train acc: 46.13530927835052, test loss: 0.6931474757194519, test acc: 54.0\n",
            "Epoch: 1 train loss: 0.6931472691064028, train acc: 55.975515463917525, test loss: 0.6931474661827087, test acc: 54.5\n",
            "Epoch: 2 train loss: 0.6931467928837255, train acc: 55.67654639175258, test loss: 0.6931473088264465, test acc: 54.5\n",
            "Epoch: 3 train loss: 0.69314790693755, train acc: 55.920103092783506, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 4 train loss: 0.6931524307457442, train acc: 55.878865979381445, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 5 train loss: 0.693150276990281, train acc: 55.81056701030928, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 6 train loss: 0.6931494142591339, train acc: 55.81958762886598, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 7 train loss: 0.6931484489096809, train acc: 55.80541237113402, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 8 train loss: 0.6931485232618666, train acc: 55.82860824742268, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 9 train loss: 0.6931468070167857, train acc: 56.05927835051546, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 10 train loss: 0.6931496545211556, train acc: 55.94845360824742, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 11 train loss: 0.6931471492826324, train acc: 56.045103092783506, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 12 train loss: 0.6931454453271689, train acc: 56.027061855670105, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 13 train loss: 0.6931500803564012, train acc: 55.769329896907216, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 14 train loss: 0.6931457513386441, train acc: 56.03092783505155, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 15 train loss: 0.6931447257700655, train acc: 56.11340206185567, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 16 train loss: 0.6931535466430113, train acc: 55.71778350515464, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 17 train loss: 0.6931449389949287, train acc: 56.13659793814433, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 18 train loss: 0.6931474393176049, train acc: 55.86984536082474, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 19 train loss: 0.6931497897069478, train acc: 55.84278350515464, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 20 train loss: 0.693147248828534, train acc: 56.045103092783506, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 21 train loss: 0.6931480163151456, train acc: 55.89819587628866, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 22 train loss: 0.6931454158320869, train acc: 55.95360824742268, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 23 train loss: 0.6931477195208835, train acc: 55.93427835051546, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 24 train loss: 0.6931453648301744, train acc: 55.993556701030926, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 25 train loss: 0.693145639503125, train acc: 55.9110824742268, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 26 train loss: 0.6931475075249819, train acc: 55.96262886597938, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 27 train loss: 0.693149740548478, train acc: 55.920103092783506, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 28 train loss: 0.6931447233121419, train acc: 56.14561855670103, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 29 train loss: 0.6931498831080407, train acc: 55.878865979381445, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 30 train loss: 0.6931469925900096, train acc: 56.08118556701031, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 31 train loss: 0.6931506843911004, train acc: 55.77319587628866, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 32 train loss: 0.6931468500304467, train acc: 56.05798969072165, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 33 train loss: 0.6931521173604985, train acc: 55.84664948453608, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 34 train loss: 0.6931491285255275, train acc: 55.89819587628866, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 35 train loss: 0.6931530470700608, train acc: 55.71778350515464, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 36 train loss: 0.6931474042921951, train acc: 55.86469072164948, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 37 train loss: 0.6931473502178782, train acc: 55.8930412371134, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 38 train loss: 0.6931526482719736, train acc: 55.76030927835052, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 39 train loss: 0.6931498149006637, train acc: 55.878865979381445, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 40 train loss: 0.6931474927774409, train acc: 55.884020618556704, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 41 train loss: 0.6931482068042165, train acc: 55.81056701030928, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 42 train loss: 0.6931466017801737, train acc: 56.13659793814433, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 43 train loss: 0.6931447712416502, train acc: 56.0360824742268, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 44 train loss: 0.6931497024506638, train acc: 55.96134020618557, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 45 train loss: 0.6931508632050347, train acc: 55.878865979381445, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 46 train loss: 0.6931470134823593, train acc: 55.952319587628864, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 47 train loss: 0.6931470749304467, train acc: 56.016752577319586, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 48 train loss: 0.693146156896021, train acc: 55.94845360824742, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 49 train loss: 0.6931497583684233, train acc: 55.75, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 50 train loss: 0.6931479272154188, train acc: 55.824742268041234, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 51 train loss: 0.69314644447307, train acc: 55.920103092783506, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 52 train loss: 0.693149262482358, train acc: 55.76417525773196, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 53 train loss: 0.6931482522758012, train acc: 55.95747422680412, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 54 train loss: 0.6931500735971117, train acc: 55.71907216494845, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 55 train loss: 0.6931484962247082, train acc: 56.00773195876289, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 56 train loss: 0.6931499218203357, train acc: 55.77835051546392, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 57 train loss: 0.6931484446083147, train acc: 55.85180412371134, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 58 train loss: 0.6931474466913754, train acc: 56.021907216494846, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 59 train loss: 0.6931469649383702, train acc: 55.98969072164948, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 60 train loss: 0.6931507058979309, train acc: 55.85180412371134, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 61 train loss: 0.6931473489889165, train acc: 55.98969072164948, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 62 train loss: 0.6931493792337241, train acc: 55.865979381443296, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 63 train loss: 0.6931483825457465, train acc: 55.93427835051546, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 64 train loss: 0.6931486369408283, train acc: 55.82860824742268, test loss: 0.6931472969055176, test acc: 54.625\n",
            "Epoch: 65 train loss: 0.6931471763197908, train acc: 56.08634020618557, test loss: 0.6931472969055176, test acc: 54.625\n"
          ]
        }
      ],
      "source": [
        "model_0_results = training_loop(model=model_1,\n",
        "                                    train=train_dataloader,\n",
        "                                    test=test_dataloader,\n",
        "                                    optimizer=optimizer,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    acc=accuracy_fn,\n",
        "                                    epochs=100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "13ezRq_bETDlcV-JdBpBSEcGLYfzPE_Of",
      "authorship_tag": "ABX9TyMuzWJ/icsT+Sqgcc79Q+lD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "19ebbc34c50d4381a52463e325866084": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f59cddc62593405b8e69f4d0f8e7f709",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a43d2cece97740babd30026584f9bb69",
            "value": 54
          }
        },
        "32e96f9d1d3942d8aa34701b52ce8e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90fad83f49df455cb4b5fb8c908c3fc8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7be73d379e3f4cb581b9e48e05f9aa3b",
            "value": " 54/100 [4:31:11&lt;3:44:15, 292.51s/it]"
          }
        },
        "44c7cf2da5464a7b8270f80aadb8cbf7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7be73d379e3f4cb581b9e48e05f9aa3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90fad83f49df455cb4b5fb8c908c3fc8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0deb4d2da224b679e8730772dcc2689": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43d2cece97740babd30026584f9bb69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e57e6fc953674c188bc5ad791c1a171e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1e054fa691d48c58528d45c4d584cb5",
              "IPY_MODEL_19ebbc34c50d4381a52463e325866084",
              "IPY_MODEL_32e96f9d1d3942d8aa34701b52ce8e56"
            ],
            "layout": "IPY_MODEL_a0deb4d2da224b679e8730772dcc2689"
          }
        },
        "f1e054fa691d48c58528d45c4d584cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44c7cf2da5464a7b8270f80aadb8cbf7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f2e728ea8a4b4927b484d7c3f1a7b3d7",
            "value": " 54%"
          }
        },
        "f2e728ea8a4b4927b484d7c3f1a7b3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f59cddc62593405b8e69f4d0f8e7f709": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}